{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dCMF\n",
    "Example of running the \"dcmf\" module with the use provided parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import time\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dcmf import dcmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the sample dataset\n",
    "\n",
    "This directory contains a sample synthetic dataset generated for the augmented setting of Fig 1(c) in the [paper](https://arxiv.org/abs/1811.11427).\n",
    "You can download the sample data from [here](https://drive.google.com/open?id=1EFF_kuOIg2aYyOGZY_peX3NziqCSxxP1) and unzip it to the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_no = 4\n",
    "data_dir = f\"../data/MIMIC/sample{sample_no}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data_dir:  ../data/MIMIC/sample4/\n"
     ]
    }
   ],
   "source": [
    "#Loads the dataset into a dict\n",
    "#Note: This dataset contains 5-folds for the matrix X_12 (matrix R below)\n",
    "num_folds = 1\n",
    "#\n",
    "pp = pprint.PrettyPrinter()\n",
    "print(\"Loading data from data_dir: \",data_dir)\n",
    "U1 = pkl.load(open(data_dir+\"X_12.pkl\",'rb'))\n",
    "V1 = pkl.load(open(data_dir+\"X_31.pkl\",'rb'))\n",
    "# V1 = pkl.load(open(data_dir+\"X_26.pkl\",'rb'))\n",
    "# W1 = pkl.load(open(data_dir+\"X_53.pkl\",'rb'))\n",
    "R_temp_dict = {}\n",
    "for fold_num in np.arange(1,num_folds+1):\n",
    "    Rtrain = pkl.load(open(data_dir+'/X_23_train_fold_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rtrain = Rtrain\n",
    "    Rtrain_idx = pkl.load(open(data_dir+'/X_23_train_idx_'+str(fold_num)+'.pkl','rb')) \n",
    "    Rtest = pkl.load(open(data_dir+'/X_23_test_fold_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rtest_idx = pkl.load(open(data_dir+'/X_23_test_idx_'+str(fold_num)+'.pkl','rb'))\n",
    "    Rdoublets = pkl.load(open(data_dir+'/R_doublets_'+str(fold_num)+'.pkl','rb'))\n",
    "    R_temp_dict[fold_num] = {\"Rtrain\":Rtrain,\"Rtrain_idx\":Rtrain_idx,\"Rtest\":Rtest,\"Rtest_idx\":Rtest_idx,\"Rdoublets\":Rdoublets}\n",
    "#\n",
    "data_dict = {\"U1\":U1,\"V1\":V1,\"R\":R_temp_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1.shape:  (5911, 1321)\n",
      "V1.shape:  (596, 5911)\n",
      "R.shape:  (1321, 596)\n"
     ]
    }
   ],
   "source": [
    "print(\"U1.shape: \",U1.shape)\n",
    "print(\"V1.shape: \",V1.shape)\n",
    "print(\"R.shape: \",data_dict['R'][1]['Rtrain'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the required data structures\n",
    "\n",
    "Here we construct the data structures required as input to the dcmf API\n",
    "\n",
    "#### *entity matrix relationship graph *\n",
    "\n",
    "- **G**: dict, keys are entity IDs and values are lists of associated matrix IDs\n",
    "\n",
    "#### * training data*\n",
    "- **X_data**: dict, keys are matrix IDs and values are (1) np.array, or (2) dict, (if this matrix is in validation set **X_val**) with validation set IDs as keys & values as np.array\n",
    "- **X_meta**: dict, keys are matrix IDs and values are lists of the 2 associated entity IDs\n",
    "\n",
    "#### *validation data*\n",
    "- **X_val**: dict, keys are IDs of the matrices that are part of validation set and values are dict with validation set IDs as keys and values are (1) scipy.sparse matrix, or (2) list of triplets corresponding to the validation entries (if you would like to perform classification and measure AUC)  \n",
    "**Note**: To perform K folds cross validation, use K validation sets for the corresponsing matrix/matrices. In the example below, we used a single validation set with ID \"1\" for each of the matrices with IDs \"X1\" and \"X2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {\n",
    "    \"e1\":[\"X1\",\"X3\"],\\\n",
    "    \"e2\":[\"X1\",\"X2\"],\\\n",
    "    \"e3\":[\"X2\",\"X3\"]\n",
    "}\n",
    "    #\"e6\":[\"X4\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = {\n",
    "    \"X1\":{\"1\":U1},\\\n",
    "    \"X2\":{\"1\":data_dict['R'][1][\"Rtrain\"]},\\\n",
    "    \"X3\":V1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = {\n",
    "    \"X1\":[\"e1\",\"e2\"],\\\n",
    "    \"X2\":[\"e2\",\"e3\"],\\\n",
    "    \"X3\":[\"e3\",\"e1\"]}\n",
    "    #\"X5\":[\"e5\",\"e3\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rtest_triplets1 = [[1,1,1],[2,2,0]]\n",
    "# Rtest_triplets2 = [[1,1,1],[3,3,0],[1,2,0],[0,1,0],[0,2,0],[0,3,0]]\n",
    "Rtest_triplets1 = [[0, 65, 1], [0, 3, 0]]\n",
    "Rtest_triplets2 = [[0, 64, 1], [0, 66, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = {\n",
    "    \"X1\":{\"1\":Rtest_triplets1},\n",
    "    \"X2\":{\"1\":Rtest_triplets2}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *dCMF network construction - hyperparameters*\n",
    "\n",
    "- **kf**: float, in the range (0,1) \n",
    "- **k**: int, entity representation or encoding size. Refer Appendix A in the [paper](https://arxiv.org/abs/1811.11427) for info about how k and kf are used in the dCMF network construction. \n",
    "- **e_actf**: str, autoencoder's encoding activation function.\n",
    "- **d_actf**: str, autoencoder's decoding activation function. Supported functions are \"tanh\",\"sigma\",\"relu\",\"lrelu\"\n",
    "- **is_linear_last_enc_layer**: bool, True to set linear activation for the bottleneck/encoding generation layer \n",
    "- **is_linear_last_dec_layer**: bool, True to set linear activation for the output/decoding generation layer \n",
    "- **num_chunks**: int, number of training batches to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = 0.5\n",
    "k = 100\n",
    "e_actf = \"tanh\"\n",
    "d_actf = \"tanh\"\n",
    "is_linear_last_enc_layer = False\n",
    "is_linear_last_dec_layer = False\n",
    "num_chunks = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Optimization/training - hyperparamteres*\n",
    "\n",
    "- **learning_rate**: float, Adam optimizer's learning rate\n",
    "- **weight_decay**: float, Adam optimizers's weight decay (L2 penalty)\n",
    "- **max_epochs**: int, maximum number of training epochs at which the training stops \n",
    "- **convg_thres**: float, convergence threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.05\n",
    "max_epochs = 5\n",
    "convg_thres = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Hyperparamteres related to pre-training*\n",
    "\n",
    "- **is_pretrain**: bool, True for pretraining \n",
    "- **pretrain_thres**: bool, pre-training convergence thresholsd\n",
    "- **max_pretrain_epochs**: int, maximum number of pre-training epochs at which the training stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pretrain=True\n",
    "pretrain_thres= 0.1\n",
    "max_pretrain_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Parameters related to validation*\n",
    "\n",
    "- **val_metric**: str, Validation performance metric. Supported metrics: [\"rmse\",\"r@k\",\"p@k\",\"auc\"]. Where,  \n",
    "     *rmse* - Root [mean square error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)  \n",
    "     *r@k* - Recall@k. Refer section 5.2's sub-section \"Evaluation metric\" in the [paper](https://arxiv.org/abs/1811.11427)      \n",
    "     *p@k* - Probability@k. Refer section 5.3's sub-section \"Evaluation metric\" in the [paper](https://arxiv.org/abs/1811.11427)      \n",
    "     *auc* - [Area under the curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "    \n",
    "- **is_val_transpose**: bool, True if the reconstructed matrix has to be transposed before computing the validation performance\n",
    "- **at_k**: int, the value of k if the **val_metric** is either \"r@k\" or \"p@k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric = \"auc\"\n",
    "is_val_transpose = True\n",
    "at_k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *GPU - parameters *\n",
    "\n",
    "- **is_gpu**: bool, True if pytorch tensors storage and operations has to be done in GPU\n",
    "- **gpu_ids**: str, Comma separated string of CUDA GPU ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gpu = False\n",
    "gpu_ids = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Instantiating the dCMF model...*\n",
    "- Initializes dCMF after validating the input data and the (hyper)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcmf_base.__init__ - start\n",
      "dcmf_base.__init__ - end\n",
      "#\n",
      "dCMF:\n",
      "---\n",
      "#\n",
      "dCMF: \n",
      "#\n",
      "learning_rate:  0.001\n",
      "weight_decay:  0.05\n",
      "convg_thres:  0.1\n",
      "max_epochs:  5\n",
      "isPretrain:  True\n",
      "pretrain_thres:  0.1\n",
      "max_pretrain_epochs:  2\n",
      "num_chunks:  2\n",
      "k:  100\n",
      "kf:  0.5\n",
      "e_actf:  tanh\n",
      "d_actf:  tanh\n",
      "is_gpu:  False\n",
      "gpu_ids:  1\n",
      "num entities:  3\n",
      "num matrices:  3\n",
      "num_val_sets:  1\n",
      "X_val #matrices:  2\n",
      "val_metric (used only if X_val #matrices > 0):  auc\n",
      "at_k (used only if X_val #matrices > 0 and val_metric is r@k or p@k):  10\n",
      "is_val_transpose:  True\n",
      "is_linear_last_enc_layer:  False\n",
      "is_linear_last_dec_layer:  False\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "dcmf_model = dcmf(G, X_data, X_meta,\\\n",
    "            num_chunks=num_chunks,k=k, kf=kf, e_actf=e_actf, d_actf=d_actf,\\\n",
    "            learning_rate=learning_rate, weight_decay=weight_decay, convg_thres=convg_thres, max_epochs=max_epochs,\\\n",
    "            is_gpu=is_gpu,gpu_ids=gpu_ids,is_pretrain=is_pretrain, pretrain_thres=pretrain_thres,\\\n",
    "            max_pretrain_epochs=max_pretrain_epochs,X_val=X_val,val_metric=val_metric,\\\n",
    "            is_val_transpose=is_val_transpose, at_k=at_k,\\\n",
    "            is_linear_last_enc_layer=is_linear_last_enc_layer,is_linear_last_dec_layer=is_linear_last_dec_layer,num_val_sets=num_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Fitting... *\n",
    "- Performs the input transformation and network construction\n",
    "- (Pre-trains and) trains the model to obtain the entity representations\n",
    "- Reconstruct the input matrices using the entity representations obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## fold_num:  1  ##\n",
      "dcmf_base.__init__ - start\n",
      "dcmf_base.__init__ - end\n",
      "#\n",
      "dCMF: \n",
      "#\n",
      "learning_rate:  0.001\n",
      "weight_decay:  0.05\n",
      "convg_thres:  0.1\n",
      "max_epochs:  5\n",
      "isPretrain:  True\n",
      "pretrain_thres:  0.1\n",
      "max_pretrain_epochs:  2\n",
      "num_chunks:  2\n",
      "k:  100\n",
      "kf:  0.5\n",
      "e_actf:  tanh\n",
      "d_actf:  tanh\n",
      "is_gpu:  False\n",
      "gpu_ids:  1\n",
      "num entities:  3\n",
      "num matrices:  3\n",
      "num_val_sets:  1\n",
      "X_val #matrices:  2\n",
      "val_metric (used only if X_val #matrices > 0):  auc\n",
      "at_k (used only if X_val #matrices > 0 and val_metric is r@k or p@k):  10\n",
      "is_val_transpose:  True\n",
      "is_linear_last_enc_layer:  False\n",
      "is_linear_last_dec_layer:  False\n",
      "#\n",
      "dcmf - model construction - start\n",
      "__input_transformation - start\n",
      "#\n",
      "concatenated-matrix construction...\n",
      "e_id:  e1\n",
      "X_id_list:  ['X1', 'X3']\n",
      "X_id:  X1\n",
      "X[X_id].shape:  (5911, 1321)\n",
      "X_id:  X3\n",
      "X[X_id].shape:  (596, 5911)\n",
      "C_dict[e].shape:  torch.Size([5911, 1917])\n",
      "---\n",
      "e_id:  e2\n",
      "X_id_list:  ['X1', 'X2']\n",
      "X_id:  X1\n",
      "X[X_id].shape:  (5911, 1321)\n",
      "X_id:  X2\n",
      "X[X_id].shape:  (1321, 596)\n",
      "C_dict[e].shape:  torch.Size([1321, 6507])\n",
      "---\n",
      "e_id:  e3\n",
      "X_id_list:  ['X2', 'X3']\n",
      "X_id:  X2\n",
      "X[X_id].shape:  (1321, 596)\n",
      "X_id:  X3\n",
      "X[X_id].shape:  (596, 5911)\n",
      "C_dict[e].shape:  torch.Size([596, 7232])\n",
      "---\n",
      "#\n",
      "concatenated-matrix chunking...\n",
      "#\n",
      "e_id:  e3 , min_num_datapoints:  596 , num_chunks:  2\n",
      "e_id:  e3 , min_features:  596 , k:  100\n",
      "#\n",
      "e_id:  e1  C_dict[e_id].shape:  torch.Size([5911, 1917])\n",
      "C_temp_chunks_list[0].shape:  torch.Size([2956, 1917])\n",
      "---\n",
      "e_id:  e2  C_dict[e_id].shape:  torch.Size([1321, 6507])\n",
      "C_temp_chunks_list[0].shape:  torch.Size([661, 6507])\n",
      "---\n",
      "e_id:  e3  C_dict[e_id].shape:  torch.Size([596, 7232])\n",
      "C_temp_chunks_list[0].shape:  torch.Size([298, 7232])\n",
      "---\n",
      "#\n",
      "creating pytorch variables of input matrices...\n",
      "#\n",
      "__input_transformation - end\n",
      "__network_construction - start\n",
      "__network_construction - end\n",
      "dcmf - model construction - end\n",
      "#\n",
      "__pretrain - start\n",
      "pretrain epoch:  1  total loss L:  0.2890647351741791  Took  16.8  secs.\n",
      "pretrain epoch:  2  total loss L:  0.28806471824645996  Took  24.2  secs.\n",
      "**pretrain converged**\n",
      "__pretrain - end\n",
      "#\n",
      "dcmf.fit - start\n",
      "epoch:  1  total loss L:  0.9617441594600677  Took  25.5  secs.\n",
      "epoch:  2  total loss L:  0.7366974055767059  Took  27.3  secs.\n",
      "epoch:  3  total loss L:  0.7802777886390686  Took  22.8  secs.\n",
      "**train converged**\n",
      "Computing AUC.\n",
      "Rpred.shape:  (1321, 5911)\n",
      "Rtest_triplets.shape:  (2, 3)\n",
      "Computing AUC.\n",
      "Rpred.shape:  (596, 1321)\n",
      "Rtest_triplets.shape:  (2, 3)\n",
      "#\n",
      "dcmf.fit - end\n"
     ]
    }
   ],
   "source": [
    "dcmf_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Result attributes:*\n",
    "- **out_dict_U**:  dict, keys are validation set IDs and values are dict with entity IDs as keys and np.array of entity representations/encodings as values\n",
    "- **out_dict_X_prime**: dict, keys are matrix IDs and values are matrix reconstructions\n",
    "- **out_dict_info**: dict, keys are loss/validation performance attributes and values are corresponding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['e1', 'e2', 'e3'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_U['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X1', 'X2', 'X3'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_X_prime['1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'learning_rate': 0.001,\n",
       "  'weight_decay': 0.05,\n",
       "  'convg_thres': 0.1,\n",
       "  'max_epochs': 5,\n",
       "  'is_pretrain': True,\n",
       "  'pretrain_thres': 0.1,\n",
       "  'max_pretrain_epochs': 2,\n",
       "  'num_chunks': 2,\n",
       "  'k': 100,\n",
       "  'kf': 0.5,\n",
       "  'e_actf': 'tanh',\n",
       "  'd_actf': 'tanh',\n",
       "  'is_linear_last_enc_layer': False,\n",
       "  'is_linear_last_dec_layer': False},\n",
       " 'num_val_sets': 1,\n",
       " 'loss_all_folds': {'1': [0.02807197067886591,\n",
       "   0.07087323069572449,\n",
       "   0.187986321747303,\n",
       "   0.007273016730323434,\n",
       "   0.41838957369327545,\n",
       "   0.06768366694450378]},\n",
       " 'loss_all_folds_avg_tuple': [0.02807197067886591,\n",
       "  0.07087323069572449,\n",
       "  0.187986321747303,\n",
       "  0.007273016730323434,\n",
       "  0.41838957369327545,\n",
       "  0.06768366694450378],\n",
       " 'loss_all_folds_avg_sum': 0.7802777804899961,\n",
       " 'val_metric': 'auc',\n",
       " 'val_perf_all_folds': {'1': {'X1': 0.0, 'X2': 0.0}},\n",
       " 'val_perf_all_folds_avg': {'X1': 0.0, 'X2': 0.0},\n",
       " 'val_perf_all_folds_total': {'1': 0.0},\n",
       " 'val_perf_all_folds_total_avg': 0.0,\n",
       " 'E': 3,\n",
       " 'M': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmf_model.out_dict_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_emb = list(dcmf_model.out_dict_U['1'].values())[0].detach().numpy()\n",
    "disease_emb = list(dcmf_model.out_dict_U['1'].values())[1].detach().numpy()\n",
    "drug_emb = list(dcmf_model.out_dict_U['1'].values())[2].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003116</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>0.095826</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>-0.028238</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.049606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038036</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.063154</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>0.088627</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>-0.002649</td>\n",
       "      <td>0.079266</td>\n",
       "      <td>0.008935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.055435</td>\n",
       "      <td>0.096376</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>0.057421</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>-0.006704</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038259</td>\n",
       "      <td>0.034903</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>0.061920</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.079968</td>\n",
       "      <td>0.006919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001896</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>-0.005436</td>\n",
       "      <td>-0.049697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>0.062594</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.079234</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001191</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>-0.028639</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>-0.049880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039982</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.063094</td>\n",
       "      <td>0.088260</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.078456</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>0.007841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002614</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.054303</td>\n",
       "      <td>0.098030</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.054201</td>\n",
       "      <td>-0.028288</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>-0.048991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039248</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.064502</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.088151</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.077926</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.080253</td>\n",
       "      <td>0.007153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.003116  0.042935  0.053690  0.095826  0.010394 -0.002317  0.054300   \n",
       "1 -0.002405  0.044990  0.055435  0.096376  0.009969 -0.000587  0.057421   \n",
       "2 -0.001896  0.042640  0.054686  0.096711  0.009165 -0.003492  0.054875   \n",
       "3 -0.001191  0.043862  0.055083  0.097234  0.008968 -0.001827  0.054547   \n",
       "4 -0.002614  0.043560  0.054303  0.098030  0.009182 -0.000323  0.054201   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.028238 -0.004080 -0.049606  ... -0.038036  0.034357  0.063154  0.061753   \n",
       "1 -0.029114 -0.006704 -0.046754  ... -0.038259  0.034903  0.063888  0.061920   \n",
       "2 -0.029136 -0.005436 -0.049697  ... -0.039336  0.035139  0.062594  0.061336   \n",
       "3 -0.028639 -0.003009 -0.049880  ... -0.039982  0.035260  0.065551  0.063094   \n",
       "4 -0.028288 -0.003900 -0.048991  ... -0.039248  0.037008  0.064502  0.063143   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.088627  0.000102  0.077342 -0.002649  0.079266  0.008935  \n",
       "1  0.089260  0.002405  0.075944  0.001103  0.079968  0.006919  \n",
       "2  0.088494  0.000219  0.078663 -0.002022  0.079234  0.008409  \n",
       "3  0.088260  0.001949  0.078456 -0.002426  0.078826  0.007841  \n",
       "4  0.088151  0.002409  0.077926 -0.003148  0.080253  0.007153  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_emb_df = pd.DataFrame(patient_emb)\n",
    "patient_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5911, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014093</td>\n",
       "      <td>-0.047882</td>\n",
       "      <td>0.092390</td>\n",
       "      <td>0.099943</td>\n",
       "      <td>-0.074168</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>0.080090</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030044</td>\n",
       "      <td>-0.127665</td>\n",
       "      <td>-0.024481</td>\n",
       "      <td>-0.034066</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>-0.023032</td>\n",
       "      <td>-0.050521</td>\n",
       "      <td>-0.040707</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>0.030234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017447</td>\n",
       "      <td>-0.045624</td>\n",
       "      <td>0.091778</td>\n",
       "      <td>0.092480</td>\n",
       "      <td>-0.079177</td>\n",
       "      <td>0.041846</td>\n",
       "      <td>0.081640</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.023557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024132</td>\n",
       "      <td>-0.116535</td>\n",
       "      <td>-0.029018</td>\n",
       "      <td>-0.024768</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>-0.042414</td>\n",
       "      <td>-0.044521</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017035</td>\n",
       "      <td>-0.045878</td>\n",
       "      <td>0.091906</td>\n",
       "      <td>0.093344</td>\n",
       "      <td>-0.078686</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>0.081515</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024811</td>\n",
       "      <td>-0.117990</td>\n",
       "      <td>-0.028352</td>\n",
       "      <td>-0.025958</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>-0.013845</td>\n",
       "      <td>-0.043386</td>\n",
       "      <td>-0.043979</td>\n",
       "      <td>0.082885</td>\n",
       "      <td>0.039573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011115</td>\n",
       "      <td>-0.049749</td>\n",
       "      <td>0.092818</td>\n",
       "      <td>0.106393</td>\n",
       "      <td>-0.069750</td>\n",
       "      <td>0.060975</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035229</td>\n",
       "      <td>-0.137342</td>\n",
       "      <td>-0.020517</td>\n",
       "      <td>-0.041961</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>-0.032121</td>\n",
       "      <td>-0.057587</td>\n",
       "      <td>-0.037306</td>\n",
       "      <td>0.101559</td>\n",
       "      <td>0.021001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018333</td>\n",
       "      <td>-0.045093</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.090610</td>\n",
       "      <td>-0.080483</td>\n",
       "      <td>0.039343</td>\n",
       "      <td>0.082051</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.025178</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022528</td>\n",
       "      <td>-0.113794</td>\n",
       "      <td>-0.030241</td>\n",
       "      <td>-0.022452</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>-0.010134</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>-0.045428</td>\n",
       "      <td>0.078973</td>\n",
       "      <td>0.043489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.014093 -0.047882  0.092390  0.099943 -0.074168  0.052060  0.080090   \n",
       "1  0.017447 -0.045624  0.091778  0.092480 -0.079177  0.041846  0.081640   \n",
       "2  0.017035 -0.045878  0.091906  0.093344 -0.078686  0.042992  0.081515   \n",
       "3  0.011115 -0.049749  0.092818  0.106393 -0.069750  0.060975  0.078798   \n",
       "4  0.018333 -0.045093  0.091629  0.090610 -0.080483  0.039343  0.082051   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.021332 -0.000255  0.017155  ... -0.030044 -0.127665 -0.024481 -0.034066   \n",
       "1  0.014429  0.002047  0.023557  ... -0.024132 -0.116535 -0.029018 -0.024768   \n",
       "2  0.015157  0.001740  0.022737  ... -0.024811 -0.117990 -0.028352 -0.025958   \n",
       "3  0.027255 -0.002288  0.011671  ... -0.035229 -0.137342 -0.020517 -0.041961   \n",
       "4  0.012664  0.002672  0.025178  ... -0.022528 -0.113794 -0.030241 -0.022452   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.003162 -0.023032 -0.050521 -0.040707  0.092297  0.030234  \n",
       "1  0.002858 -0.012564 -0.042414 -0.044521  0.081603  0.040826  \n",
       "2  0.002887 -0.013845 -0.043386 -0.043979  0.082885  0.039573  \n",
       "3  0.003406 -0.032121 -0.057587 -0.037306  0.101559  0.021001  \n",
       "4  0.002763 -0.010134 -0.040426 -0.045428  0.078973  0.043489  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_emb_df = pd.DataFrame(disease_emb)\n",
    "disease_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1321, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.061985</td>\n",
       "      <td>-0.080801</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.089628</td>\n",
       "      <td>-0.019293</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.094996</td>\n",
       "      <td>0.021540</td>\n",
       "      <td>-0.024506</td>\n",
       "      <td>-0.021499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085503</td>\n",
       "      <td>-0.111388</td>\n",
       "      <td>-0.037245</td>\n",
       "      <td>-0.016952</td>\n",
       "      <td>0.070906</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>-0.033870</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>-0.089275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.078831</td>\n",
       "      <td>-0.094036</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.111642</td>\n",
       "      <td>-0.038221</td>\n",
       "      <td>0.071943</td>\n",
       "      <td>0.104433</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>-0.041212</td>\n",
       "      <td>-0.017292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087705</td>\n",
       "      <td>-0.144672</td>\n",
       "      <td>-0.032274</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>0.081794</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>-0.055025</td>\n",
       "      <td>0.069337</td>\n",
       "      <td>0.119441</td>\n",
       "      <td>-0.099637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.082099</td>\n",
       "      <td>-0.096387</td>\n",
       "      <td>0.032347</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>-0.041661</td>\n",
       "      <td>0.074954</td>\n",
       "      <td>0.106350</td>\n",
       "      <td>0.029257</td>\n",
       "      <td>-0.044435</td>\n",
       "      <td>-0.016447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088090</td>\n",
       "      <td>-0.150883</td>\n",
       "      <td>-0.031251</td>\n",
       "      <td>-0.015440</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>-0.059041</td>\n",
       "      <td>0.069629</td>\n",
       "      <td>0.122105</td>\n",
       "      <td>-0.101702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067145</td>\n",
       "      <td>-0.084992</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.096156</td>\n",
       "      <td>-0.024824</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>0.097621</td>\n",
       "      <td>0.023562</td>\n",
       "      <td>-0.029543</td>\n",
       "      <td>-0.020060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086161</td>\n",
       "      <td>-0.121429</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.016658</td>\n",
       "      <td>0.074005</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.040456</td>\n",
       "      <td>0.068403</td>\n",
       "      <td>0.109886</td>\n",
       "      <td>-0.092269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.066525</td>\n",
       "      <td>-0.084537</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.095527</td>\n",
       "      <td>-0.024146</td>\n",
       "      <td>0.060102</td>\n",
       "      <td>0.097306</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>-0.028843</td>\n",
       "      <td>-0.020232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086108</td>\n",
       "      <td>-0.120274</td>\n",
       "      <td>-0.035765</td>\n",
       "      <td>-0.016785</td>\n",
       "      <td>0.073679</td>\n",
       "      <td>-0.001913</td>\n",
       "      <td>-0.039837</td>\n",
       "      <td>0.068335</td>\n",
       "      <td>0.109438</td>\n",
       "      <td>-0.091941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.061985 -0.080801  0.012557  0.089628 -0.019293  0.055401  0.094996   \n",
       "1 -0.078831 -0.094036  0.029251  0.111642 -0.038221  0.071943  0.104433   \n",
       "2 -0.082099 -0.096387  0.032347  0.116039 -0.041661  0.074954  0.106350   \n",
       "3 -0.067145 -0.084992  0.017696  0.096156 -0.024824  0.060600  0.097621   \n",
       "4 -0.066525 -0.084537  0.017240  0.095527 -0.024146  0.060102  0.097306   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.021540 -0.024506 -0.021499  ... -0.085503 -0.111388 -0.037245 -0.016952   \n",
       "1  0.028042 -0.041212 -0.017292  ... -0.087705 -0.144672 -0.032274 -0.015788   \n",
       "2  0.029257 -0.044435 -0.016447  ... -0.088090 -0.150883 -0.031251 -0.015440   \n",
       "3  0.023562 -0.029543 -0.020060  ... -0.086161 -0.121429 -0.035609 -0.016658   \n",
       "4  0.023427 -0.028843 -0.020232  ... -0.086108 -0.120274 -0.035765 -0.016785   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.070906 -0.005747 -0.033870  0.068399  0.105988 -0.089275  \n",
       "1  0.081794  0.008261 -0.055025  0.069337  0.119441 -0.099637  \n",
       "2  0.083925  0.010872 -0.059041  0.069629  0.122105 -0.101702  \n",
       "3  0.074005 -0.001429 -0.040456  0.068403  0.109886 -0.092269  \n",
       "4  0.073679 -0.001913 -0.039837  0.068335  0.109438 -0.091941  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_emb_df = pd.DataFrame(drug_emb)\n",
    "drug_emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7828, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df = pd.concat([patient_emb_df, disease_emb_df, drug_emb_df], ignore_index = True, axis = 0)\n",
    "emb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003116</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>0.095826</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>-0.028238</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.049606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038036</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.063154</td>\n",
       "      <td>0.061753</td>\n",
       "      <td>0.088627</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>-0.002649</td>\n",
       "      <td>0.079266</td>\n",
       "      <td>0.008935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.055435</td>\n",
       "      <td>0.096376</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>0.057421</td>\n",
       "      <td>-0.029114</td>\n",
       "      <td>-0.006704</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038259</td>\n",
       "      <td>0.034903</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>0.061920</td>\n",
       "      <td>0.089260</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.079968</td>\n",
       "      <td>0.006919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001896</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.096711</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>-0.005436</td>\n",
       "      <td>-0.049697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039336</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>0.062594</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.079234</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.001191</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.097234</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>0.054547</td>\n",
       "      <td>-0.028639</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>-0.049880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039982</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.063094</td>\n",
       "      <td>0.088260</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.078456</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.078826</td>\n",
       "      <td>0.007841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002614</td>\n",
       "      <td>0.043560</td>\n",
       "      <td>0.054303</td>\n",
       "      <td>0.098030</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.054201</td>\n",
       "      <td>-0.028288</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>-0.048991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039248</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.064502</td>\n",
       "      <td>0.063143</td>\n",
       "      <td>0.088151</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.077926</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.080253</td>\n",
       "      <td>0.007153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.003116  0.042935  0.053690  0.095826  0.010394 -0.002317  0.054300   \n",
       "1 -0.002405  0.044990  0.055435  0.096376  0.009969 -0.000587  0.057421   \n",
       "2 -0.001896  0.042640  0.054686  0.096711  0.009165 -0.003492  0.054875   \n",
       "3 -0.001191  0.043862  0.055083  0.097234  0.008968 -0.001827  0.054547   \n",
       "4 -0.002614  0.043560  0.054303  0.098030  0.009182 -0.000323  0.054201   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0 -0.028238 -0.004080 -0.049606  ... -0.038036  0.034357  0.063154  0.061753   \n",
       "1 -0.029114 -0.006704 -0.046754  ... -0.038259  0.034903  0.063888  0.061920   \n",
       "2 -0.029136 -0.005436 -0.049697  ... -0.039336  0.035139  0.062594  0.061336   \n",
       "3 -0.028639 -0.003009 -0.049880  ... -0.039982  0.035260  0.065551  0.063094   \n",
       "4 -0.028288 -0.003900 -0.048991  ... -0.039248  0.037008  0.064502  0.063143   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.088627  0.000102  0.077342 -0.002649  0.079266  0.008935  \n",
       "1  0.089260  0.002405  0.075944  0.001103  0.079968  0.006919  \n",
       "2  0.088494  0.000219  0.078663 -0.002022  0.079234  0.008409  \n",
       "3  0.088260  0.001949  0.078456 -0.002426  0.078826  0.007841  \n",
       "4  0.088151  0.002409  0.077926 -0.003148  0.080253  0.007153  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"emb_MIMIC_sample_{sample_no}.dat\", \"w\") as file:\n",
    "    file.write(\"\\n\")\n",
    "    for idx, row in emb_df.iterrows():\n",
    "        emb = row[:].astype(np.float32)\n",
    "        emb_str = ' '.join(emb.astype(str))\n",
    "        file.write(f'{idx}\\t{emb_str}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
